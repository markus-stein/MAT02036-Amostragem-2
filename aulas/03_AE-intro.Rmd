---
title: "MAT02036 - Amostragem 2"
subtitle: "Aula 03 - Amostragem Estratificada - Introdução e Estimação" 
author: "Markus Stein"
institute: "Departamento de Estatística, IME/UFRGS"
date: "2022/2"
type: "lecture"
# fontsize: 10pt
output:
  xaringan::moon_reader:
    # css: ["assets/remark.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: [center, middle]
---

```{r libs, echo=FALSE, message=FALSE, warning=FALSE}
library(xaringanExtra)
library(emo)
library(fontawesome)
library(kableExtra)
```

```{r xaringan-logo, echo=FALSE}
# install.packages("remotes")
# remotes::install_github('yihui/xaringan')
# remotes::install_github("gadenbuie/xaringanExtra")
# xaringanExtra::use_logo(
#   image_url = "https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/xaringan.png"
# )
xaringanExtra::use_logo( here::here('img/logo_dest.png'))
```

### *Housekeeping*

* Aproveitem o momento presencial para tirar dúvidas

* Se estivéssemos no ensino remoto ou à distância

  + vocês poderiam estar somente ouvindo, sem interação
  
  + ou assistindo vídeos e material em outro momento
  
* Depois das aulas, rever material da aula passada

  + fazer exercícios
  
  + se preparar para a próxima aula

---

## Aula passada `r emo::ji("disk")`

* Variável $R_i$ indicadora do evento '**inclusão** da unidade $i$ na amostra $s$'. 
$$R_i = \begin{cases} 1, & i \in s \\ 0, & i \notin s \end{cases}, \forall i \in U.$$

* Probabilidades de inclusão de **primeira ordem**.
$$\pi_i (s) = P(i \in s) = \sum_{s \ni i} p(s) = P( R_i = 1) = E_p( R_i), \forall i \in U$$
 
* Probabilidades de inclusão de **segunda ordem**, denotadas $\pi_{ij}$, dadas por 
$$\pi_{ij} = P \left[ (i,j) \in s \right] = \sum_{s \ni \left( i,j \right)} p(s) = P \left( R_{ij} = 1 \right) = E_p \left(  R_{ij} \right), \forall (i,j) \in U,$$

* Variância e covariância de $R$
$$Var_p( R_i) = \pi_i (1 - \pi_i) \: \: \:  \text{e} \: \: \:  Cov_p( R_i, R_j) = \pi_{ij} - \pi_i \pi_j.$$

---

## Aula passada `r emo::ji("disk")`

* **Estimador linear** do total $T$: $\widehat Y_w = \sum_{i \in s} w_i y_i = \sum_{i \in U} R_i w_i y_i$.

* Para que $\widehat T_w$ seja **sempre** não viciado:
$$E_p \left( \widehat T_w \right) = T \Leftrightarrow \sum_{i \in U} E_p \left( R_i \right) w_i y_i = \sum_{i \in U} y_i \Leftrightarrow \sum_{i \in U} \pi_i w_i y_i = \sum_{i \in U} y_i.$$
  
  + Válida para quaisquer $y_i$ se $\pi_i \times w_i = 1, \forall i \in U$.

* Estimador **Horvitz-Thompson**: com pesos básicos $d_i$, para o total $Y$ 
$$\widehat T_{HT} = \sum_{i \in s} {d_i}{y_i} = \sum_{i \in s} {\pi_i}^{-1} y_i = \sum_{i \in s} {y_i}/{\pi_i}$$

* O estimador linear do total $\widehat T_w = \sum_{i \in s} w_i y_i$ será **sempre não viciado** se: 
$$w_i = {\pi_i}^{-1} = {1}/{\pi_i} = d_i, \forall i \in U.$$

* **Distribuição amostral**, resultados assintóticos, ...

---

## Aula passada `r emo::ji("disk")`

Estimadores AASc | Estimadores AASs
--|--
$\widehat T_{AASc} = \frac {N}{n} \sum_{i \in s} y_i = N \, \overline{y}$ | $\widehat{T}_{AASs} = \frac {N}{n} \sum_{i \in s} y_i= N \overline{y}$
$\overline{y} = \frac{1}{n} \sum_{i \in s} y_i$ | $\overline{y} = \frac{1}{n} \sum_{i \in s} y_i = \widehat{\overline T}_{AASs}$
$\widehat{Var}_{AASc}(\widehat T_{AASC}) = N^2 \widehat S_y^2 / n$ | $\widehat{Var}_{AASs}(\widehat T_{AASs}) = N^2 \left( \frac{1}{n} - \frac{1}{N} \right) \widehat S^2_y$ 
$\widehat{Var}_{AASc}(\overline{y}) = \widehat S_y^2 / n$ | $\widehat{Var}_{AASs} (\overline{y}) = \left( \frac{1}{n} - \frac{1}{N} \right) \widehat S^2_y$
em que $\widehat S^2_y = \frac{1}{n-1} \sum_{i\in s} ({y_i-\overline{y}})^2$.


Estimadores $HT$ | Variâncias dos Estimadores $HT$
--|--
$\widehat T_{HT} = \sum_{i\in s} d_i y_i = \sum_{i \in s} {y_i}/{\pi_i}$ | $\widehat{Var}_{HT}(\widehat T_{HT}) =  \sum_{i\in s} \sum_{j\in s} \frac{(\pi_{ij} - \pi_i \pi_j)}{\pi_{ij}} \left( \frac{y_i}{\pi_i} \frac{y_j}{\pi_j} \right)$
$\overline y_{HT} = \widehat T_{HT}/N = \sum_{i\in s}d_i y_i/N$ | $\widehat{Var}_{HT}(\overline y_{HT}) = \widehat{Var}_{HT}(\widehat T_{HT})/{N^2}$


<!-- --- -->

<!-- ## Aula passada `r emo::ji("disk")` -->

<!-- **Plano amostral** sob AASs -->

<!-- * Existem $\binom{N}{n} = \frac{N!}{n!(N-n)!}$ amostras distintas em $S$, $p(s) = 1/\binom{N}{n}, \forall\, s\in S$. -->

<!-- * $\pi_i = n / N > 0$, $\forall \,i \in U$, desde que $n > 0$. -->

<!-- * $f = n / N$ é chamada de **fração amostral** ou **taxa de amostragem**. -->

<!-- * $\pi_{ij} = \frac{n(n-1)}{N(N-1)} > 0, \forall i \ne j \in U$. -->

<!--   + Estimação de variância sem vício requer $\pi_{ij} > 0$,  $\forall\, i,j \in U$. -->

<!-- * **Variável de inclusão** $R_i$ sob AASs -->

<!-- $E_{AAS} [R_i] = \frac{n}{N}$  -->

<!-- $V_{AAS} [R_i] = \frac{n}{N} \left(1-\frac{n}{N}\right)$   -->

<!-- $COV_{AAS} [R_i, R_j ] = \frac{n(n-1)}{N(N-1)} - \left(\frac{n}{N}\right)^2 = \frac{n}{N}\left(1-\frac{n}{N}\right)\left(-\frac{1}{N-1}\right)$ -->

<!-- --- -->

<!-- ## Aula passada `r emo::ji("disk")` -->

<!-- 1. O termo $(1 - n/N) = (1 - f)$ é chamado de **fator de correção para população finita**.  -->

<!--   + Quando $n/N \rightarrow 1$, o tamanho da amostra se aproximando do tamanho da população, então $(1 - n/N) \rightarrow 0$.  -->

<!--   + Ou seja: com amostras grandes as variâncias das estimativas tendem a ser pequenas.  -->

<!-- 2. Se a fração amostral $f = n/N$ for pequena (da ordem de 1% ou 2%), então a **correção de população finita** pode ser ignorada, pois $(1 – f) \doteq 1$.  -->

<!--   + Quando $f \doteq 0$, a AASse AASc (com reposição) tem comportamento semelhante em relação à precisão das estimativas.  -->

<!--   + *Intuitivamente*, sempre que $n$ for muito **pequeno** em relação ao $N$ a probabilidade de uma unidade $i$ da população ser selecionada mais de uma vez é pequena. -->

<!-- --- -->

<!-- ## Aula passada `r emo::ji("disk")` -->

<!-- * Distribuição da média amostral -->

<!-- * Repetições do plano amostral $p(s)$ segundo *AASs*, $\overline{y}$ tem uma **distribuição de probabilidades exata**, que **depende**: -->
<!--   + da distribuição de $y$ na população,  -->
<!--   + do tamanho da amostra $n$ e  -->
<!--   + do plano amostral $p(s)$, que neste caso, é AASs.  -->

<!-- * Isto resulta numa situação complicada, que pode ser resolvida considerando a **Distribuição Assintótica da Média Amostral**. -->

<!-- * Se $n$ for **grande** e $f = n/N$ for pequena, o *Teorema Central do Limite* (Hajeck, 1960) sugere uma aproximação -->
<!-- $$\frac{ \overline {y} - E_{AAS} (\overline{y}) }{ \sqrt{V_{AAS} (\overline{y})}} = \frac{ \overline{y} - \overline{Y} }{ \sqrt{ \left( \frac{1}{n} - \frac{1}{N} \right) S^2_y}} \approx Normal(0;1),$$ -->

---

class: inverse, middle, center

# Amostragem Estratificada

---

## Amostragem Estratificada `r fa("people-group", fill = "red")``r fa("people-group", fill = "blue")`
### O método geral

* **Amostragem estratificada** - **AE** utiliza **informação auxiliar** relevante para **dividir** a população $U$ em $H$ **grupos** disjuntos e exaustivos,

  + geralmente mais homogêneos em relacão à(s) variável(is) de interesse, chamados *estratos*. 
--

* Assumimos uma partição da população $U$ ( em $H$ subconjuntos mutuamente exclusivos e exaustivos).

  + $U_h$: unidades pertencentes ao estrato $h$, para $h=1, 2, ...,H$.

$$U =  \bigcup_{h=1}^H U_h  \hspace{1cm} \text{e} \hspace{1cm} U_h \cap U_k = \emptyset, \forall h \ne k.$$
--

* Seja $N_h$ o tamanho de $U_h$, O tamanho total da população é dado por

$$N = N_1 + \dots + N_h + \dots + N_H = \sum_{h=1}^H N_h.$$

---

## Amostragem Estratificada `r fa("people-group", fill = "red")``r fa("people-group", fill = "blue")`
### O método geral

* Para ser viável, as **variáveis de estratificação** (usadas para dividir a população em estratos) precisam: 

  + estar **disponíveis** para todas as unidades da **população** da qual se vai selecionar a amostra.
--

Exemplo: 

* variáveis geográficas, 
  + como as **unidades da federação** ou **municípios**, 
--

* outros tipos, 

  + tais como sexo, idade, 
  
  + número de empregados na empresa, área do estabelecimento, etc. 

---

## Amostragem Estratificada `r fa("people-group", fill = "red")``r fa("people-group", fill = "blue")`
### O método geral

* Em seguida, é feita a **seleção** de amostras **dentro** de cada um dos **estratos**, de forma **independente**. 
  
  + A amostra final é formada então pela união das amostras selecionadas em cada um dos estratos. 

--

* Selecione uma amostra $s_h$ de tamanho $n_h$, com $n_h > 0$, segundo um plano amostral $p_h(s_h)$ *independentemente* dentro de cada estrato $h$, 

  + $n =  \sum_{h=1}^{H} n_h$ é o tamanho total da amostra selecionada. 

--

* Fica assim assegurado que cada estrato tem sua população representada na amostra completa dada por: $s = s_1 \cup \dots \cup s_h \cup \dots \cup s_H$. 

  + Pela definição dos estratos, as amostras nos vários estratos também são conjuntos mutuamente exclusivos, $s_h \cap s_k = \emptyset, \, h \ne k$. 

---

## Exemplo `r emo::ji("workout")`
Considere uma pesquisa feita em uma população de 8 domicílios, onde são conhecidas as variáveis renda familiar (Y) e local do domicílio (L), com os códigos A para região alta e B para baixa (B).

```{r}
N <- 8
domicilio <- 1:N
y <- c( 13, 17, 6, 5, 10, 12, 19, 6)
l <- c( "B", "A", "B", "B", "B", "A", "A", "B")
```
--
```{r, echo=FALSE}
tabela <- rbind(domicilio, y, l)
kable(tabela)
```
--

`r fa("1", fill = "steelblue")` Calcule $Var( \overline y)$ sob AASc, para estimar $\overline Y = \frac{T}{N} = \frac{ \sum_i \in U y_i}{N}$, com $n=4$.

`r fa("2", fill = "steelblue")` Calcule $Var( \overline y_{AES})$, para $\overline y_{AES} = \frac{N_A \: \overline y_A + N_B \: \overline y_B}{N}$ (usando $L$ como variável estratificadora), com amostra $n_h=2$ por estrato.

`r fa("3", fill = "steelblue")` Compare as variâncias dos dois planos (Efeito do Plano Amostral $EPA$).

---

## Exemplo `r emo::ji("workout")`
Resolução:
.pull-left[ 
$N=8$ domicílios, $N_A=3$, $N_B=8$;  
$L$: localidade domicílio, $H=2$;  
$Y$: renda familiar. 
]
.pull-right[ 
```{r, echo=FALSE, }
kable(tabela)
```
]

.pull-left[ 
`r fa("1", fill = "steelblue")` Sob AASc $Var( \overline y) = Var_y/n$,
]
.pull-right[ 
```{r}
n <- 4
Ybarra <- mean(y)
vary <- sum( (y-Ybarra)^2) / N
varybarra <- vary / n
```
]
--

.pull-left[ 
`r fa("2", fill = "steelblue")` Para $Var( \overline{y}_{AES})$, precisamos $Var( \overline{y}_A) = `r emo::ji("question")`$ e $Var( \overline{y}_B) = `r emo::ji("question")`$,
]
.pull-right[ 
```{r}
yA <- y[l=="A"]; yB <- y[l=="B"]
N_A <- length(yA); N_B <- length(yB);
nA <- nB <- 2
```
<!-- YbarraA <- mean(yA); YbarraB <- mean(yB) -->
<!-- varyA <- sum( (yA-YbarraA)^2) / N_A; varyB <- sum( (yB-YbarraB)^2) / N_B -->
<!-- varybarraA <- varyA / nA; varybarraB <- varyB / nB -->
<!-- ``` -->
]
--

.pull-left[ 
`r fa("3", fill = "steelblue")` Então $EPA = \frac{Var( \overline{y}_{AES})}{Var( \overline{y}_{AASc})} = `r emo::ji("question")`$
]
.pull-right[ 
```{r}
## ... continuar...
```
]

---


## Amostragem Estratificada `r fa("people-group", fill = "red")``r fa("people-group", fill = "blue")`
### O método geral

* A independência da amostragem nos diferentes **estratos** permite olhar como **populações separadas**. Uma implementação segue o algoritmo:

1. Defina a **estratificação** da população $U$.    

2. Defina o **método para selecionar** a amostra em cada um dos estratos.    

3. **Selecione a amostra** de cada estrato usando o método definido em (2).    

4. **Reúna as amostras** dos vários estratos formando a amostra da pesquisa.

---

## Amostragem Estratificada `r fa("people-group", fill = "red")``r fa("people-group", fill = "blue")`
### Importância

`r fa("1", fill = "steelblue")`. Quando os **estratos** formam **domínios “naturais”** ou de interesse, 

  + ex. regiões geográficas, tipos de empresas (farmácias, supermercados, lojas de departamentos) etc., 

  + a estratificação garante a seleção de amostras de tamanhos especificados em todos os estratos formados, 

  + permite controlar a precisão esperada de estimativas para subgrupos da população de pesquisa definidos como estratos ou agregações de estratos.    

--

`r fa("2", fill = "steelblue")`. Pode tornar a **amostra mais “representativa”** e 

  + assegurar que todas as partes (estratos) relevantes da população sejam incluídas na amostra.     

---

## Amostragem Estratificada `r fa("people-group", fill = "red")``r fa("people-group", fill = "blue")`
### Importância

`r fa("3", fill = "steelblue")`. Para **melhorar a eficiência** amostral, **reduzir a variância** dos estimadores dos parâmetros de interesse:

  + quanto maior for a **homogeneidade dentro dos estratos**, 
  
  + mais a estratificação permite aumentar a precisão de estimativas, em comparação com planos de igual tamanho de amostra que não usam estratificação.   

--

`r fa("4", fill = "steelblue")`. Se necessário usar **métodos diferentes de coleta** em diferentes subgrupos da população; 

  + a estratificação favorece a administração e implementação da coleta em pesquisas onde as condições de pesquisa variam entre os estratos; 
  
  + ex. estratos podem ser formados de modo a viabilizar o emprego de modos alternativos de coleta (presencial, telefone, internet, etc.). 

---

## Amostragem Estratificada `r fa("people-group", fill = "red")``r fa("people-group", fill = "blue")`
### Características

* Para pesquisas em que a **estimação** é objetivo:
  + o **processo de amostragem** e **estimação** deve ser replicado separadamente em cada estrato.

--

* Para pesquisas onde **não são de interesse** resultados **por estrato**,
  + **parâmetros dos estratos** são estimados separadamente, de acordo com o plano amostral adotado,
  + então as **estimativas** são **agregadas** para obter estimativas referentes ao conjunto da população.

--

* Como **desvantagens** potenciais do método
  + requerer a **reestruturação do cadastro** antes da amostragem.
  + apenas **uma estratificação** é possível e, uma vez fixada a estratificação, a amostragem vai depender dela de forma direta.
  + subdividir em **muitos estratos** pode levar a amostras muito pequenas em cada estrato e complicações como não resposta, ou 'instabilidade nas estimativas'.

---

class: inverse, middle, center

# Tipos de Estratificação

---

## Tipos de Estratificação

`r fa("1", fill = "steelblue")`. *Natural* - quando os estratos são iguais a subgrupos da população para os quais se requer estimativas com precisão controlada.

  + O processo requer essencialmente ouvir os clientes ou usuários dos resultados da pesquisa. 
  
  + São eles que devem indicar que subgrupos da população requerem estimativas com precisão controlada. 
  
  + Ex.  pesquisas do IBGE, que além de produzir resultados para o país como um todo, têm que produzir também resultados por unidades da federação. 
  
  + Estas são então *estratos naturais* nas pesquisas, que passam a ter suas amostras planejadas de modo a ter seleção independente em cada unidade da federação, sendo tais amostras de tamanhos suficientes para estimar com a precisão desejada em cada uma.

---

## Tipos de Estratificação

`r fa("2", fill = "steelblue")`. *Estatística* - quando os estratos são definidos como subgrupos homogêneos da população, visando aumentar eficiência na estimação para a população como um todo. 

  + Não há interesse específico na estimação de parâmetros dos estratos formados.

  + sua formação pode ser feita empregando métodos que visam a otimizar os efeitos da estratificação. 
  
  + Alguns destes métodos são apresentados na sequência.

---

## Tipos de Estratificação

* Na **prática**, não é incomum encontrar aplicações onde a estratificação usada numa pesquisa **combina os dois tipos**.

  + Ex. Na **amostragem de pesquisas econômicas estruturais do IBGE** as empresas são estratificadas por **unidade da federação** e **tipo de atividade econômica**, definindo assim seus **estratos naturais**.
  
  + Dentro destes estratos, para **aumentar a eficiência** da amostragem, as empresas são estratificadas por faixas de tamanho, usando a variável **pessoal ocupado**, **estratificação estatística**, pois tais pesquisas não buscam estimar parâmetros populacionais nestes estratos de tamanho (dentro dos estratos naturais). Ver IBGE(2000).

Há diversos fatores que influenciam a **eficiência na AE**: 

- A(s) variável(is) de estratificação.     
- O número de estratos.     
- A determinação dos limites dos estratos.    
- A alocação da amostra nos estratos.     
- O método de seleção da amostra em cada estrato.

---

## Tipos de Estratificação

* Para **estratificação natural**, a escolha da(s) variável(is) de estratificação se dá considerando TODAS as variáveis disponíveis necessárias para definir os domínios de interesse.

* No caso da **estratificação estatística**, a escolha deve priorizar, entre as variáveis disponíveis, as que são as *melhores preditoras* da(s) variável(is) de interesse da pesquisa. Para ganhar eficiência a ideia é tornar os valores da(s) variável(is) de estudo dentro de cada estrato mais similares / homogêneos possíveis; minimizar a *variância dentro dos estratos*.

* Nos dois casos é **fundamental** ter acesso a **cadastro(s)** com informações completas sobre variáveis auxiliares que são necessárias para estratificar a população de forma eficiente. 


---

class: inverse, middle, center

# Exemplos de possíveis planos de **AE**

---

## Exemplos de possíveis planos
#### Amostragem com estratos definidos por conveniência administrativa

* Considere uma **população de passageiros** chegando a um **terminal marítimo**, 
  + navios carregam tanto passageiros viajando com seus **automóveis** como passageiros que viajam **a pé**.
  + ex. *UK International Passenger Survey* (Horsfield, 2017).
  
* Objetivo: selecionar uma amostra de passageiros para **estimar a média dos gastos feitos na viagem** por passageiro. 

.pull-left[
**Automóvel** - estrato 1
* Ex. *Amostragem Sistemática* para selecionar um de cada $K$ automóveis cruzando um ponto de fluxo na saída do navio. 
* As unidades de amostragem são os automóveis (com 1 ou mais passageiros), **Amostragem conglomerada**.
]
.pull-right[
**Passageiros a pé** - estrato 2  
* Ex. *Amostragem Binomial* para selecionar passageiros ao passarem por um ponto de fluxo na saída do navio.
* As unidades de amostragem seriam os passageiros individualmente. 
] 

---

## Exemplos de possíveis planos
#### Amostragem Estratificada por Corte - AEC

* Muito usado em pesquisas de **estabelecimentos** ou **instituições**, em populações onde há grande **assimetria** das principais variáveis de interesse.

* Estratos formados por **partes da população** onde existe **grande heterogeneidade** ou que **concentram grande parte do total** de uma ou mais variáveis de interesse, porém compostas de um **número relativamente pequeno** de unidades populacionais, 
  + Chamado *estrato certo*, nele se faz um **censo**. Nos demais estratos são pesquisadas amostras de suas unidades. 

* Ex. **pesquisas econômicas** na área da **indústria** onde um número pequeno de estabelecimentos industriais é responsável por grande parte do valor da produção. 
  + Neste caso, a precisão das estimativas de totais populacionais produzidas pode ser maior com **AEC** em comparação com **AAS**.
  + Como no **estrato certo** é feito um **censo**, não há variabilidade devida ao uso de amostragem nesse estrato (variância nula do total 'estimado' nesse estrato).

---

## Exemplos de possíveis planos
#### Amostragem estratificada simples 

* **Diferentes planos amostrais** podem ser empregados nos diversos estratos, mas isso é **pouco comum na prática**. O mais comum é usar um mesmo tipo de amostragem nos vários estratos definidos.

* A *Amostragem Estratificada Simples - AES* é o caso mais simples, em que uma **AASs** é selecionada em cada um dos estratos. 
  + Neste caso, deve estar disponível um cadastro que permita alocar as unidades da população $U$ nos estratos definidos, conhecer os tamanhos dos estratos, e o cadastro deve estar organizado de forma a permitir a seleção da amostra em cada um dos estratos.

* Veremos agora resultados para **AES**, mas o mesmo tipo de enfoque pode ser adaptado quando for utilizado qualquer outro método de seleção nos estratos, 
  + tais como *Amostragem Sistemática*, *Amostragem Binomial*, *Amostragem com PPT*, etc. 
  + A **seleção** é **independente** nos diferentes estratos, basta fazer as estimativas utilizando as fórmulas adequadas ao método de seleção em cada estrato, então agregar os resultados dessas estimativas de forma adequada.

---

class: inverse, middle, center

# AES, parâmetros e estimadores

---

## Amostragem estratificada simples
### Método de seleção

* Para cada estrato $h = 1, 2, \dots, H$, selecione por AASs uma amostra $s_h$ de tamanho $1 \le n_h \le N_h$ das $N_h$ unidades do estrato $U_h$ (independente da seleção feita nos outros estratos).

* Qualquer algoritmo para seleção de amostras AASs pode ser empregado para a seleção das amostras nos estratos. 

* O conjunto de todas as amostras possíveis $S_{AES}$ é formado por amostras da forma: 

$$s = s_1 \cup \dots \cup s_h \cup \dots \cup s_H = .$$

  + O tamanho é dado pelo produto dos tamanhos dos conjuntos de amostras possíveis em cada um dos estratos. 

$$\#S_{AES} = \# s_1 \times \ldots \times \# s_H = \prod_{h=1}^H {N_h \choose n_h} = \nu.$$

---

## Amostragem estratificada simples
### Método de seleção

* Assim, na **AASs** em cada estrato, temos o plano amostral:

$$p_h(s_h) = 1 \Big/ \binom {N_h}{n_h} = \binom {N_h}{n_h}^{-1}, \forall h = 1, 2, \dots, H.$$

* Em consequência, o plano amostral $p_{AES}(s)$ é dado por:

$$p_{AES}(s) = \prod_{h=1}^H p_h(s_h) = \prod_{h=1}^H \binom {N_h}{n_h}^{-1}$$

onde $s \in S_{AES}$.

O *tamanho total da amostra* é: 
$$n = n_1 + n_2 + \dots + n_H.$$

---

## Amostragem estratificada simples 
### Parâmetros nos estratos

* **Total** populacional do **estrato** $h$:

$$T_h =  \sum_{i \in U_h} y_{i}$$

* **Média** populacional do **estrato** $h$

$$\overline {Y_h} = T_h / N_h = \frac {1} {N_h} \sum_{i \in U_h} y_{i}$$ 

* **Variância** do **estrato** $h$

$$S_{h}^2 = \frac {1} {N_h-1} \sum_{i \in U_h}  (y_i - \overline {Y_h})^2 \: \: \: \: \text{ou} \: \: \: \: Var_{h} =  \frac{N_h - 1}{N_h} S_{h}^2.$$

---

## Amostragem estratificada simples 
### Parâmetros globais

* O **total populacional**:
$$T = \sum_{h=1}^H Y_h = \sum_{h=1}^H N_h \overline {Y_h}$$

* A **média populacional**:
$$\overline Y = T/N = \frac {1} {N} \sum_{h=1}^H N_h \overline {Y_h} = \sum_{h=1}^H W_h \overline Y_h,$$
onde $W_h = N_h/N$ é o *peso* da média do estrato $h$ na composição de $\overline Y$.

* A **variância populacional** pode ser escrita como 
$$S_y^2 = \frac {1} {N-1} \sum_{h=1}^H \sum_{i \in U_h} \left( y_i - \overline Y \right)^2 \: \: \: \: \text{ou} \: \: \: \: Var_y =  \frac{1}{N} \sum_{h=1}^H \sum_{i \in U_h} \left( y_i - \overline Y \right)^2 = \frac{N-1}{N} S_y^2.$$

---

## Amostragem estratificada simples 
### Parâmetros globais

* A variância populacional $S_y^2$ pode ser escrita como:

$$\begin{eqnarray} 
S_y^2 & = & \frac {1} {N-1} \sum_{h=1}^H \sum_{i \in U_h} \left( y_i - \overline Y \right)^2 \\ 
& = & \frac {1} {N-1} \sum_{h=1}^H \sum_{i \in U_h} \left[ \left(y_i - \overline {Y_h} \right) + \left(\overline {Y_h} - \overline Y \right) \right]^2 \\ 
& = & \frac {1} {N-1} \sum_{h=1}^H (N_h - 1) S_{h}^2 + \frac {1} {N-1} \sum_{h=1}^{H} {N_h} \left( \overline {Y_h} - \overline Y \right)^2 \\ 
 & = & S_D^2 + S_E^2, 
 \end{eqnarray}$$
onde $S_D^2 =   \sum_{h=1}^H  \frac {N_h - 1}{N - 1} S_{h}^2 \: \: \: \text{e} \: \: \: S_E^2 =  \sum_{h=1}^{H} \frac {N_h}{N - 1} \left( \overline {Y_h} - \overline Y \right)^2$

* ou 
$$Var_y = \sum_{h=1}^H  W_h Var_h + \sum_{h=1}^{H} W_h \left( \overline {Y_h} - \overline Y \right)^2 = Var_D + Var_E$$
---

## Amostragem estratificada simples 
### Parâmetros globais

* $S_y^2  = S_D^2 + S_E^2$ ou $Var_y = Var_D + Var_E$ sugerem uma **decomposição** útil da variância total da variável $y$ na população. 

  + As componentes são conhecidas como **Variância Dentro** e **Variância Entre** estratos. 
  
* Selecionar **amostras** de forma **independente** em **todos** os **estratos**, a amostragem estratificada **elimina** a componente de **variação** **entre** os estratos ao estimar parâmetros do conjunto da população, ex. o total ou a média. 

* Para uma **variância total** $S_y^2$ **fixada**, **minimizar** a **Variância Dentro** $S_D^2$, ao definir estratos homogêneos (em relação à variável de interesse), deve reduzir grande parte da variação relevante para a estimação. 

---

## Amostragem estratificada simples 
### Estimação no estrato $h$

Temos **amostragem independentemente** em cada estrato, então os seguintes **estimadores**:

* do **total** $T_h$ do **estrato** $h$,
$$\widehat T_h = \sum_{i \in s_h} d_i y_i = \frac{N_h}{n_h} \sum_{i \in s_h} y_i = N_h \overline y_h;$$  

onde $d_i = N_h / n_h = \pi_i^{-1}$ é o peso das unidades $i$ dentro do estrato $h$. 

* da **média** $\overline Y_h$ do **estrato** $h$,
$$\overline y_h = \frac{1}{n_h} \sum_{i \in s_h} y_i;$$ 

* da **variância** $S_{h}^2$ ou $Var_{h}$ do estrato $h$, 
$$\widehat S_{h}^2 = \frac{1}{n_h - 1} \sum_{i \in s_h} \left( y_i - \overline y_h \right)^2 = s^2_h.$$

---

## Amostragem estratificada simples 
### Estimação no estrato $h$ 

* Se temos **AASs** de $n_h$ unidades **dentro do estrato** $h$, **sabemos que** são válidas as seguintes propriedades: 

  + $E_{AES} \left(\widehat T_h \right) = T_h$

  + $E_{AES} \left( \overline y_h\right) = \overline {Y_h}$

  + $E_{AES} \left(\widehat S_{h}^2 \right) = S^2_h$ $\hspace{1cm} \Rightarrow \widehat S_{h}^2$ é **ENV** de $S^2_h$ sob **AASs**

* Os resultados decorrem das **propriedades** de **estimadores** sob **AASs**. 

* Sabemos mostrar esses resultados`r emo::ji("question")``r emo::ji("question")``r emo::ji("question")`

* E na **AASc**`r emo::ji("question")``r emo::ji("question")``r emo::ji("question")`
  
  + $E_{AES} \left(\widehat S_{h}^2 \right) = Var_{h}$ $\hspace{1cm} \Rightarrow \widehat S_{h}^2$ é **ENV** de $Var_h$ sob **AASc**
  
---

## Amostragem estratificada simples 
### Estimação no estrato $h$


* **Variâncias** de estimadores de média e total por estrato na **AASs**:

Total | Média
--|--
$Var_{AES} \left( \widehat T_h \right) = N_h^2 Var_{AES} \left( \overline y_h \right)$ | $Var_{AES} \left( \overline y_h \right) = \left( \frac{1}{n_h} - \frac{1}{N_h} \right) S^2_h$
$\widehat{Var}_{AES} \left( \widehat T_h \right) = N_h^2 \widehat{Var}_{AES} \left( \overline y_h \right)$ | $\widehat{Var}_{AES} \left( \overline y_h \right) = \left( \frac{1}{n_h} - \frac{1}{N_h} \right)\widehat S_{h}^2$


--
* E na **AASc**`r emo::ji("question")``r emo::ji("question")``r emo::ji("question")`

--

Total | Média
--|--
$Var_{AESc} \left( \widehat T_h \right) = N_h^2 Var_{AESc} \left( \overline y_h \right)$ | $Var_{AESc} \left( \overline y_h \right) = \frac{1}{n_h} Var_h$
$\widehat{Var}_{AESc} \left( \widehat T_h \right) = N_h^2 \widehat{Var}_{AESc} \left( \overline y_h \right)$ | $\widehat{Var}_{AESc} \left( \overline y_h \right) = \frac{1}{n_h} \widehat S_h^2$


---

## Amostragem estratificada simples
### Estimação de parâmetros globais

* O estimador do total $T$: $\hspace{1cm} \widehat T_{AES} = \sum_{h=1}^{H} \widehat T_h  = \sum_{h=1}^{H} N_h \overline y_h.$ 

* O estimador da média $\overline Y$: $\hspace{1cm} \overline y_{AES} = \sum_{h=1}^{H}W_h \overline y_h = \sum_{h=1}^{H} \frac{N_h}{N} \overline y_h.$

O **estimador** da média populacional sob **AES** é **não viciado**, isto é: 

$$E_{AES} \left( \overline y_{AES} \right) = \overline Y$$

Isto segue porque $E_{AES} \left (\overline y_h\right) = \overline {Y_h}$, $\forall \,h=1,...,H$, e

$$E_{AES} \left( \sum_{h=1}^{H} W_h \overline y_h \right) = \sum_{h=1}^{H} W_h E_{AES} (\overline y_h) = \sum_{h=1}^{H} W_h \overline {Y_h} = \overline Y.$$

---

## Amostragem estratificada simples
### Estimação de parâmetros globais

* Para estimar a **variância do estimador** do **total** e da **média**, respectivamente, (dado **AASs** dentro dos estratos)
.center[
$Var_{AES} \left( \widehat T_{AES} \right) = \sum_{h=1}^{H} {N_h^2} \left( \frac{1}{n_h} - \frac {1}{N_h} \right) S^2_h$  
e  
$Var_{AES} \left( \overline y_{AES} \right) = \sum_{h=1}^{H} W_h^2 Var_{AES} \left( \overline y_h\right ) = \sum_{h=1}^{H} \frac {N_h^2}{N^2} \left( \frac{1}{n_h} - \frac {1}{N_h} \right) S^2_h,$
]

--

* temos os **ENV**s com as expressões dadas por 
.center[
$\widehat{Var}_{AES} \left( \widehat T_{AES} \right) = \sum_{h=1}^{H} N_h^2 \left( \frac{1}{n_h} - \frac{1}{N_h} \right)\widehat S_{h}^2$  
e  
$\widehat{Var}_{AES} \left( \overline y_{AES} \right) = \sum_{h=1}^{H} \frac {N_h^2}{N^2} \left( \frac{1}{n_h} - \frac{1}{N_h} \right)\widehat S_{h}^2$.
]

--

* E quanto a **AASc**`r emo::ji("question")``r emo::ji("question")``r emo::ji("question")`

<!-- --- -->

<!-- ## Amostragem estratificada simples  -->
<!-- ### Estimação de parâmetros globais -->

<!-- $\widehat Y_{AES} =  \sum_{h=1}^{H} \widehat Y_h = \sum_{h=1}^{H} N_h \overline y_h$ e $\widehat V_{AES} \left( \widehat Y_{AES} \right) = \sum_{h=1}^{H} N_h^2 \left( \frac{1}{n_h} - \frac{1}{N_h} \right)\widehat S_{h}^2$   -->

<!-- -- -->

<!-- $ \overline y_{AES} = \sum_{h=1}^{H} \frac{N_h}{N} \overline y_h =  \sum_{h=1}^{H} W_h \overline y_h$ e $\widehat V_{AES} \left( \overline y_{AES} \right) =  \sum_{h=1}^{H} W_h^2 \left( \frac{1}{n_h} - \frac{1}{N_h} \right)\widehat S_{h}^2$ -->

<!-- .footnote[Casos particulares de calibração são o estimador de razão combinada e o estimador de razão separada, usuais para o total populacional $(Y)$ no caso de **AES**.] -->

---

## Amostragem estratificada simples 
### Intervalo de confiança para a média $\overline Y$

Se $n = \sum_{h=1}^{H} n_h$ for grande, então o Teorema Central do Limite se aplica:

$$\frac{\overline y_{AES} - \overline Y}{\sqrt{\widehat{Var}_{AES} \left( \overline y_{AES} \right)}} \approx Normal(0;1)$$

Logo, um intervalo de confiança de nível $1-\alpha$ para $\overline Y$ é dado por:

$$IC_{AES} (\overline Y; 1-\alpha) = \left[ \overline y_{AES} \mp z_{\alpha/2} \sqrt{\widehat{Var}_{AES} \left( \overline y_{AES} \right)} \right]$$

---

## Amostragem estratificada simples 
### Intervalo de confiança para a média do estrato $\overline Y_h$

Se os tamanhos de amostras *por estratos* $n_h$ são suficientemente grandes, o Teorema Central do Limite também indica que:

$$\frac{\overline y_h - \overline {Y_h}}{\sqrt{\widehat{Var}_{AES}\left(\overline y_h\right)}} \approx Normal(0;1)$$
 
e então um intervalo de confiança de nível $1-\alpha$ para $\overline {Y_h}$ é dado por:

$$IC_{AES} (\overline {Y_h}; 1-\alpha) = \left[ \overline y_h \mp z_{\alpha/2} \sqrt{\widehat{Var}_{AES} \left( \overline y_h \right)} \right]$$

---

## Para casa `r emo::ji("house")`

* Continuar o Exemplo.
* Mostrar $E_{AES} \left( \widehat T_{AES} \right) = T$.
* Encontre $Var_{AES} \left( \widehat T_{AES} \right)$, tanto para **AASs** quanto para **AASc**.
* Fazer exercícios.
* Rever os slides.
* Ler a partir seção 11.3 do livro 'Amostragem: Teoria e Prática Usando R'.

## Próxima aula `r emo::ji("stats")`

* Amostragem Estratificada
  + Alocação de amostras nos estratos

  <!-- + normalidade assintótica e intervalos de confiança -->
  <!-- + Tamanho de amostra -->
  <!-- + Estimação de proporções -->
  
* Laboratório de `r fa("r-project", fill = "steelblue")`

---

## Muito obrigado!

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='30%', out.height='30%', paged.print=FALSE}
knitr::include_graphics(here::here('img', 'image_basu_elephant.jpg'))
```
Fonte: imagem do livro *Combined Survey Sampling Inference: Weighing of Basu's Elephants: Weighing Basu's Elephants*.

---

## Resumo da notação

Parâmetros no estrato $h$
* Total - $T_h = \sum_{i \in U_h} y_{i}$
* Média - $\overline {Y_h} = T_h / N_h = \frac {1} {N_h} \sum_{i \in U_h} y_{i}$
* Variância - $S_h^2 = \frac {1} {N_h-1} \sum_{i \in U_h}  (y_i - \overline {Y_h})^2 \: \: \: \: \text{ou} \: \: \: \: Var_h = Var_{h,y} =  \frac{N_h - 1}{N_h} S_h^2$

Parâmetros globais
* Total - $T = \sum_{h=1}^H T_h = \sum_{h=1}^H N_h \overline {Y_h}$
* Média - $\overline Y = T/N = \frac {1} {N} \sum_{h=1}^H N_h \overline {Y_h} = \sum_{h=1}^H W_h \overline Y_h$,  $W_h = N_h/N$
* Variância - $S^2 = \frac {1} {N-1} \sum_{h=1}^H \sum_{i \in U_h} \left( y_i - \overline Y \right)^2 \: \: \: \: \text{ou} \: \: \: \: Var_y =  \frac {1} {N} \sum_{h=1}^H (N_h - 1) S_{h}^2$

Decomposição da variância populacional
.center[
$S_y^2  = \frac {1} {N-1} \sum_{h=1}^H (N_h - 1) S_{h}^2 + \frac {1} {N-1} \sum_{h=1}^{H} {N_h} \left( \overline {Y_h} - \overline Y \right)^2 = S_D^2 + S_E^2$  
ou  
$Var_y = \sum_{h=1}^H  W_h Var_h + \sum_{h=1}^{H} W_h \left( \overline {Y_h} - \overline Y \right)^2 = Var_D + Var_E.$
]

---

## Resumo da notação

Estimadores no estrato $h$

Estimadores **AASc** | Estimadores **AASs**
--|--
$\widehat T_h = \frac {N_h}{n_h} \sum_{i \in s_h} y_i = N_h \overline{y}_h$ | $\widehat{T}_h = \frac {N_h}{n_h} \sum_{i \in s_h} y_i= N_h \overline{y}_h$
$\overline{y}_h = \frac{1}{n_h} \sum_{i \in s_h} y_i$ | $\overline{y}_h = \frac{1}{n_h} \sum_{i \in s_h} y_i$
$Var_{AESc} \left( \widehat T_h \right) = N_h^2 Var_{AESc} \left( \overline y_h \right)$ | $Var_{AES} \left( \widehat T_h \right) = N_h^2 Var_{AES} \left( \overline y_h \right)$
$Var_{AESc} \left( \overline y_h \right) = \frac{1}{n_h} Var_h$ | $Var_{AES} \left( \overline y_h \right) = \left( \frac{1}{n_h} - \frac{1}{N_h} \right) S^2_h$
$\widehat{Var}_{AESc} \left( \widehat T_h \right) = N_h^2 \widehat{Var}_{AESc} \left( \overline y_h \right)$ | $\widehat{Var}_{AES} \left( \widehat T_h \right) = N_h^2 \widehat{Var}_{AES} \left( \overline y_h \right)$
$\widehat{Var}_{AESc} \left( \overline y_h \right) = \frac{1}{n_h} \widehat S_h^2$ | $\widehat{Var}_{AES} \left( \overline y_h \right) = \left( \frac{1}{n_h} - \frac{1}{N_h} \right)\widehat S_{h}^2$

em que $Var_h = Var_h (y) =  \frac{N_h - 1}{N_h} S_{h}^2$ e $\widehat S_{h}^2 = \frac{1}{n_h - 1} \sum_{i \in s_h} \left( y_i - \overline y_h \right)^2.$

---

## Resumo da notação

**Estimadores globais**
* Do total $T$: $\hspace{1cm} \widehat T_{AES} = \sum_{h=1}^{H} \widehat T_h  = \sum_{h=1}^{H} N_h \overline y_h.$
* Da média $\overline Y$: $\hspace{1cm} \overline y_{AES} = \sum_{h=1}^{H}W_h \overline y_h = \sum_{h=1}^{H} \frac{N_h}{N} \overline y_h.$

**Variância do estimador** e seu **estimador**

Sob **AASc** | Sob **AASs**
--|--
$Var_{AES} \left( \widehat T_{AES} \right) = \sum_{h=1}^{H} {N_h^2} \frac{Var_h}{n_h}$ | $Var_{AES} \left( \widehat T_{AES} \right) = \sum_{h=1}^{H} {N_h^2} \left( \frac{1}{n_h} - \frac {1}{N_h} \right) S^2_h$
$Var_{AES} \left( \overline y_{AES} \right) = \sum_{h=1}^{H} W_h^2 \frac{Var_h}{n_h}$ | $Var_{AES} \left( \overline y_{AES} \right) = \sum_{h=1}^{H} W_h^2 \left( \frac{1}{n_h} - \frac {1}{N_h} \right) S^2_h$
$\widehat{Var}_{AES} \left( \widehat T_{AES} \right) = \sum_{h=1}^{H} N_h^2 \frac{\widehat S_{h}^2}{n_h}$ | $\widehat{Var}_{AES} \left( \widehat T_{AES} \right) = \sum_{h=1}^{H} N_h^2 \left( \frac{1}{n_h} - \frac{1}{N_h} \right)\widehat S_{h}^2$
$\widehat{Var}_{AES} \left( \overline y_{AES} \right) = \sum_{h=1}^{H} W_h^2 \frac{\widehat S_{h}^2}{n_h}$ | $\widehat{Var}_{AES} \left( \overline y_{AES} \right) = \sum_{h=1}^{H} W_h^2 \left( \frac{1}{n_h} - \frac{1}{N_h} \right)\widehat S_{h}^2$

---

## Referências

Slides baseados no Capítulo 11 do livro

* [Amostragem: Teoria e Prática Usando o R](https://amostragemcomr.github.io/livro/index.html)

Citações do Capítulo
* Horsfield(2017)
* IBGE(2000)



<!-- * refazer calculos para amostagem aleatoria simples com reposicao -->
<!-- * alocacao... ou lab R comparando alocação proporcional e igual tamanho -->

<!-- listas de exercicios... -->
<!-- dois aspectos da disciplina... ter flexibilidade com teoria... exercitar os conceitos com exercicios teoricos e praticos -->
